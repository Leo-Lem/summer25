## [[10. (discuss) Mueller_ICSE_2016.pdf]]
* **Summary**: Using biometrics to assess code difficulty.
* **Problem**: Lack of tooling to automatically assess code difficulty.
* **Results**
	* How do biometrics compare to traditional metrics of code quality? outperform.
	* Generalise to other companies? one-week replication study.
### Introduction
tech debt/bad code generate costs.
code reviews help, but require time and effort.
previous automated approaches insufficient, as they
- require extra information (like code history).
- do not take into account differences in code comprehension between devs.
HRV/EDA linked with task difficulty.
study: use biometrics to find code which is perceived as difficult with 10 devs in Canadian company.
results
- biometrics outperform traditional metrics and naive classifier.
- code elements perceived as more difficult contain more peer review concerns.
- helps automatically detect 50% of bugs found in code reviews.
generalisability: 1-week replication study with five devs in Swiss company. Some findings can be replicated.
### Context: Related Work and Psychological Background
1. manual detection of quality concerns.
	- lightweight code reviews provide substantial benefits.
	- require time and effort by peer developers.
2. automatic detection based on traditional metrics.
	* complexity, size, change are common.
	* oragnisational information to predict (how many devs touched a file, for example)
	* FindBugs, PMD.
	* defect prediction can be improved by micro interaction metrics (for example, ratio between edits and selects)
	* interaction logs of IDE to predict difficulty by dev.
3. use of biometrics in software dev.
	* skin, heart, breathing mainly.
	* have been used to assess mental load in software eng.
	* predict difficulty of code comprehension
cognitive load theory: intrinsic (inherent task difficulty), extrinsic (for example, code quality), germane load (effort for processing information)
more difficult task > higher cognitive load, worse performance.
biometrics can be used to approximate cognitive load.
### Methods
RQs
- biometrics to identify difficult code?
- biometrics to identify quality concerns found in peer reviews?
- biometrics compared to traditional metrics?
- sensitivity to the individual?
**Participants**: 23 to 45 years old, 3 to 22 years of experience, same project, different teams, agile. could access their biometric data and quit anytime.
**Sensors**: wristband for skin and heart, chest strap for skin, heart and breathing. wristband was optional (6/10 wore it).
**Procedure**: asked to install interaction monitoring plugin in Eclipse. put on sensors, charge after each day. continue work as regular. baseline by watching video of fish swimming in fish tank for normalisation. eclipse plugin asks each 90mins to rate difficulty of elements currently being worked with. Also on commits.
**Metrics**: biometrics, code metrics, interaction metrics, change metrics.
Outcome measures: perceived difficulty during change task (survey every 90mins in IDE), perceived difficulty at end of change task (survey after commit in IDE), code quality concerns via peer reviews (results of code reviews collected).
**Data Collection**: 116 developer work days. 1500 methods and 1500 classes were rated in perceived difficulty.
### Results: Analysis and Replication Study
only 3% of code elements perceived as difficult.
in 43% of 51.2% ~ 20% difficulty increased. changes frequent and often not perceived in traditional metrics.
RF in Weka (Java), leave-one-out evaluation. comparison with different inputs.
perceived difficulty: biometrics is better than the other approaches, combined classifier even better.
quality concerns: biometrics is even better than combined approach.
within v. across participants: not so well across participants.
replication study differences: 5 devs, switzerland, 1 week, no change metrics, no code review data.
### Discussion
**online code quality prediction**: while dev working on code. factor in individual difference.
**tool support**: could provide a tool support, suggestions like take a break based on biometrics.
**challenges**: sensor usability, privacy concerns. potential with smart watches.
**threats to validity**
- internal validity: personal traits or general stress influences biometrics. mitigated by baseline with fish tank video.
- external validity: limited number of participants. focus on java, eclipse. mitigated a little by replication study, but still very diverse field.
- construct validity: logs and biometrics as proxies are at best good approximation. but current technology limited this. also self-reporting can be problematic. limited traditional metrics due to lacking repo access.
### Conclusion
automatic determination of difficult code suggested by both studies. good opportunity for future research for integrating biometrics with rise of wearables.