{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b3e2e0",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ef8c7",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "In this exercise, your task is to classify texts using a Naive Bayes Classifier.\n",
    "\n",
    "You have two datasets: `20newsgroups.csv` and `spam_or_not_spam.csv`.\n",
    "\n",
    "`spam_or_not_spam.csv` contains e-mails that should be classified in two categories (spam and not spam). \n",
    "\n",
    "`20newsgroups.csv` contains newsgroup texts that should be classified in 20 categories.\n",
    "\n",
    "Your classifier thus should work for an arbitrary number of labels.\n",
    "\n",
    "You have to implement the following:\n",
    "\n",
    "1. TF-IDF Vectorization (TF-IDF helps to identify words that are as distinctive as possible for the respective categories);\n",
    "\n",
    "1. Naive Bayes Classifier for multinomialy distributed data using scikit-learn with a smoothing parameter;\n",
    "\n",
    "1. Pipeline that loads the data, splits it into 80\\% of training and 20\\% of test data with shuffling and random_state=42, turns the data into its vector representation using TF-IDF, trains a Naive Bayes classifier and predicts the labels for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9671670",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc434bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import _BaseNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from numpy.typing import ArrayLike\n",
    "from scipy.sparse import csr_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8683000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    confusion_matrix: ArrayLike, classes: ArrayLike, title: str\n",
    ") -> None:\n",
    "    \"\"\"Plot the confusion matrix.\n",
    "    Args:\n",
    "        confusion_matrix (ArrayLike): The confusion matrix to plot.\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(figsize=(8.27, 8.27))\n",
    "    sns.heatmap(\n",
    "        confusion_matrix,\n",
    "        ax=ax,\n",
    "        square=True,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        xticklabels=classes,\n",
    "        yticklabels=classes,\n",
    "    )\n",
    "    ax.set_xlabel(\"Prediction\", fontsize=16)\n",
    "    ax.set_ylabel(\"Truth\", fontsize=16)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe2a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(y_test: ArrayLike, y_pred: ArrayLike, classes: ArrayLike) -> None:\n",
    "    print(f\"Accuracy:\\t\\t{accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "    if len(classes) == 2:\n",
    "        print(f\"Classes:\\t\\t{classes[0]} and {classes[1]}\")\n",
    "        print(f\"--- {classes[0]} ---\")\n",
    "        print(\n",
    "            f\"Precision:\\t\\t{precision_score(y_test, y_pred, pos_label=classes[0], zero_division=0):.3f}\"\n",
    "        )\n",
    "        print(f\"Recall:\\t\\t\\t{recall_score(y_test, y_pred, pos_label=classes[0]):.3f}\")\n",
    "        print(f\"F1:\\t\\t\\t{f1_score(y_test, y_pred, pos_label=classes[0]):.3f}\")\n",
    "        print(f\"--- {classes[1]} ---\")\n",
    "        print(\n",
    "            f\"Precision:\\t\\t{precision_score(y_test, y_pred, pos_label=classes[1]):.3f}\"\n",
    "        )\n",
    "        print(f\"Recall:\\t\\t\\t{recall_score(y_test, y_pred, pos_label=classes[1]):.3f}\")\n",
    "        print(f\"F1:\\t\\t\\t{f1_score(y_test, y_pred, pos_label=classes[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db40c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_dataset(dataset_path: str) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Load a text dataset from a CSV file using pandas.\n",
    "    The CSV file should have two columns: the first column contains the text data,\n",
    "    and the second column contains the labels.\n",
    "    Args:\n",
    "        dataset_path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: A tuple containing the text data and labels.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    X = df.iloc[:, 0].to_numpy()\n",
    "    y = df.iloc[:, 1].to_numpy()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f2a72",
   "metadata": {},
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb10aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(\n",
    "    X_train: ArrayLike, X_test: ArrayLike\n",
    ") -> tuple[csr_matrix, csr_matrix]:\n",
    "    \"\"\"Vectorize the text data using TF-IDF.\n",
    "    Args:\n",
    "        X_train (ArrayLike): The training text data.\n",
    "        X_test (ArrayLike): The testing text data.\n",
    "    Returns:\n",
    "        tuple[csr_matrix, csr_matrix]: The vectorized training and testing data.\n",
    "    \"\"\"\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    return X_train_vectorized, X_test_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584f7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(X: csr_matrix, y: ArrayLike, alpha: float) -> _BaseNB:\n",
    "    \"\"\"Train a Naive Bayes classifier.\n",
    "    Args:\n",
    "        X (csr_matrix): The training vectorized data.\n",
    "        y (ArrayLike): The training labels.\n",
    "        alpha (float): The smoothing parameter.\n",
    "    Returns:\n",
    "        _BaseNB: The trained Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "def pipeline_nb_classifier(\n",
    "    path: str,\n",
    "    alpha: float = 1,\n",
    ") -> None:\n",
    "    \"\"\"Create a pipeline for text classification using Naive Bayes.\n",
    "    Args:\n",
    "        path (str): Path to the CSV file containing the dataset.\n",
    "        alpha (float): The smoothing parameter for the Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = load_text_dataset(path)\n",
    "\n",
    "    def clean_text(x): # sanitize to not crash kernel\n",
    "        non_printable = ''.join(c for c in x if c in string.printable)\n",
    "        unicode_normalized = unicodedata.normalize(\"NFKD\", non_printable)\n",
    "        return unicode_normalized\n",
    "    X = np.array([clean_text(x) for x in X])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train_vectorized, X_test_vectorized = vectorize_text(X_train, X_test)\n",
    "    clf = naive_bayes_classifier(X_train_vectorized, y_train, alpha)\n",
    "    y_pred = clf.predict(X_test_vectorized)\n",
    "    print_scores(y_test, y_pred, classes=clf.classes_)\n",
    "\n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plot_confusion_matrix(mat, clf.classes_, title=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f5701",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a665d8",
   "metadata": {},
   "source": [
    "### 20 Newsgroups dataset - Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb_classifier(\"20newsgroups.csv\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e19dc",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. What class does the Naive Bayes Classifier struggle with the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0e6a4",
   "metadata": {},
   "source": [
    "### Spam / No Spam dataset - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb_classifier(\"spam_or_not_spam.csv\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22325330",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. How many False Positives does the Naive Bayes Classifier have?\n",
    "1. How many False Negatives does the Naive Bayes Classifier have?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
