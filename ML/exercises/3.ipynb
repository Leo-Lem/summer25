{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5546d534",
   "metadata": {},
   "source": [
    "# Ridge Regression / Polynomial Expansion / k-fold Cross Validation / Validation Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef2ed5",
   "metadata": {},
   "source": [
    "In this programming exercise, you will implement a polynomial ridge regression and k-fold cross validation using only numpy. You will also plot a validation curve. DO NOT use libraries like scikit-learn or scipy.\n",
    "\n",
    "Use the template provided in this notebook to implement ridge regression, polynomial expansion, k-fold cross validation, and plot a validation curve.\n",
    "\n",
    "When done, paste the code into the quiz on Moodle and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be876cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a83f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Loads data from provided .npy files and returns the x and y values.\n",
    "    Args:\n",
    "        name (str): The file name of the .npy file to load.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The x and y values of the data. x has shape (n,) and y has shape (n,).\n",
    "    \"\"\"\n",
    "    data = np.load(name)\n",
    "    x, y = data.T\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed843b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x: ArrayLike, y: ArrayLike) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Shuffles the data using a random permutation.\n",
    "    Args:\n",
    "        x (ArrayLike): The input values of the data.\n",
    "        y (ArrayLike): The target values of the data.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The shuffled x and y values.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    n = x.shape[0]\n",
    "    indx = rng.permutation(n)\n",
    "    return x[indx], y[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ddbe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(x: ArrayLike, y: ArrayLike, w: Optional[ArrayLike] = None) -> None:\n",
    "    \"\"\"Plot the data and linear regression model.\n",
    "    Only for plotting 2D data.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n,).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        w (ArrayLike, optional): The weight and bias of a linear regression. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot the data\n",
    "    plt.plot(x, y, \".\", markersize=8, color=\"#D81B60\", label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot the prediction\n",
    "    if w is not None:\n",
    "        deg = w.shape[0]\n",
    "        x_plot = np.linspace(x.min(), x.max(), 100)\n",
    "        X_plot = np.vander(x_plot, deg)\n",
    "\n",
    "        # Set plotting range properly\n",
    "        plt.ylim((np.min(y) * 1.2, np.max(y) * 1.2))\n",
    "\n",
    "        plt.plot(x_plot, X_plot @ w, linewidth=2.5, color=\"#0BA462\", label=\"Model\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(\n",
    "    lambdas: ArrayLike,\n",
    "    train_losses: ArrayLike,\n",
    "    val_losses: Optional[ArrayLike] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plots the validation curve.\n",
    "    Args:\n",
    "        lambdas (ArrayLike): The regularization values.\n",
    "        train_losses (ArrayLike): The training losses.\n",
    "        val_losses (ArrayLike, optional): The validation losses. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(lambdas, train_losses, color=\"#D81B60\", linewidth=2.5, label=\"Train loss\")\n",
    "    if val_losses is not None:\n",
    "        plt.plot(\n",
    "            lambdas, val_losses, color=\"#1E88E5\", linewidth=2.5, label=\"Valid loss\"\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(x: ArrayLike, y: ArrayLike, lam: float = 0) -> ArrayLike:\n",
    "    \"\"\"Calculates the Ridge Regression (linear least-squares regression with l2-regularization) coefficients.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "    Returns:\n",
    "        ArrayLike: The ridge regression coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a solver for the problem from Task 1.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_features(x: ArrayLike, deg: int) -> ArrayLike:\n",
    "    \"\"\"Generates polynomial features of the input data to the specified degree.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n,).\n",
    "        deg (int): The degree of the polynomial features.\n",
    "    Returns:\n",
    "        ArrayLike: The polynomial features of the input data of shape (n, d + 1) from 0 degree to deg degree.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a polynomial feature expansion of a certain degree for the input data.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_loss(x: ArrayLike, y: ArrayLike, w: ArrayLike) -> float:\n",
    "    \"\"\"Calculates the loss of the linear least squares regression.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        w (ArrayLike): The weights of the model.\n",
    "    Returns:\n",
    "        float: The loss of the linear least squares regression.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    return np.linalg.norm(x @ w - y) ** 2 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5be12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(x: ArrayLike, y: ArrayLike, lam: float, k: int = 10) -> tuple[float, float]:\n",
    "    \"\"\"Performs k-fold cross-validation to evaluate the model's performance.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lam (float): The regularization parameter.\n",
    "        k (int, optional): The number of folds. Defaults to 10.\n",
    "    Returns:\n",
    "        tuple[float, float]: Average train and validation losses ¡¡PER DATA POINT!!.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement k-fold cross validation.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c936be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_curve_data(\n",
    "    x: ArrayLike, y: ArrayLike, lambdas: ArrayLike\n",
    ") -> tuple[int, ArrayLike, ArrayLike]:\n",
    "    \"\"\"Computes the best lambda and returns its index and train and validation losses for lambdas.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lambdas (ArrayLike): The range of lambda values to evaluate.\n",
    "    Returns:\n",
    "        int: The best lambda index based on the validation loss.\n",
    "        ArrayLike: The training losses for each lambda value.\n",
    "        ArrayLike: The validation losses for each lambda value.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a function that returns data required for plotting the validation curve.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c83ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "x_train, y_train = load_data(\"dataset_poly_train.npy\")\n",
    "x_train, y_train = shuffle_data(x_train, y_train)\n",
    "\n",
    "deg = 6\n",
    "X_train = get_polynomial_features(x_train, deg=6)\n",
    "\n",
    "# Validation curve\n",
    "lambdas = np.logspace(-9, 3, num=100, base=10)\n",
    "best_lam_idx, train_losses, val_losses = get_validation_curve_data(\n",
    "    X_train, y_train, lambdas\n",
    ")\n",
    "\n",
    "plot_validation_curve(\n",
    "    lambdas,\n",
    "    train_losses,\n",
    "    val_losses,\n",
    ")\n",
    "print(f\"Best validation error {val_losses[best_lam_idx]:.4f} \")\n",
    "print(f\"Corresponding train error {train_losses[best_lam_idx]:.4f}\")\n",
    "print(f\"Corresponding lambda {lambdas[best_lam_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on all training data with the best lambda\n",
    "w = ridge_regression(X_train, y_train, lam=lambdas[best_lam_idx])\n",
    "plot_regression(x_train, y_train, w)\n",
    "\n",
    "# Compute train and test error\n",
    "x_test, y_test = load_data(\"dataset_poly_test.npy\")\n",
    "X_test = get_polynomial_features(x_test, deg=6)\n",
    "\n",
    "train_loss = empirical_loss(X_train, y_train, w)\n",
    "test_loss = empirical_loss(X_test, y_test, w)\n",
    "print(f\"Train loss: {train_loss:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
