{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b732ecc",
   "metadata": {},
   "source": [
    "# Linear Classification / Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1cb8db",
   "metadata": {},
   "source": [
    "### Task Description\n",
    "\n",
    "You have a dataset of handwritten digits containing only two numbers, 1 and 5.\n",
    "\n",
    "You will find the training and the test data set under `dataset_numbers_train.npy` and `dataset_numbers_test.npy`.\n",
    "\n",
    "Your task is to find a good linear classifier to classify these images.\n",
    "\n",
    "If $y_i = 0$ then the $i$-th image represents a one, otherwise $y_i = 1$ represents a five.\n",
    "\n",
    "- What is your best test accuracy?\n",
    "\n",
    "You have to implement the following:\n",
    "\n",
    "1. Logistic Loss\n",
    "\n",
    "1. Logistic Regression using scikit-learn with the provided inverse of regularization strength, no intercept, and 10000 maximum number of iterations.\n",
    "\n",
    "The template provided in this notebook already has k-Fold Cross-Validation and a few other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49653456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from typing import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef801f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Loads data from provided .npy files and returns the x and y values.\n",
    "    Args:\n",
    "        name (str): The file name of the .npy file to load.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The x and y values of the data. x has shape (n,d) and y has shape (n,).\n",
    "    \"\"\"\n",
    "    data = np.load(name)\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numbers(numb: ArrayLike, tag: ArrayLike, rng: Generator = None) -> None:\n",
    "    \"\"\"Plots 8 random images of the digits 0 and 5 from the dataset.\n",
    "    Args:\n",
    "        numb (ArrayLike): The dataset containing the images of the digits.\n",
    "        tag (ArrayLike): The labels for the images in the dataset.\n",
    "        rng (Generator, optional): Random number generator. Defaults to None.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(seed=66)\n",
    "    ones = numb[tag == 0]\n",
    "    fives = numb[tag == 1]\n",
    "\n",
    "    (fig, axs) = plt.subplots(nrows=2, ncols=4)\n",
    "\n",
    "    indx = rng.integers(len(ones), size=4)\n",
    "    for ax, i in zip(axs[0], indx):\n",
    "        ax.imshow(ones[i].reshape(28, 28), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "    indx = rng.integers(len(fives), size=4)\n",
    "    for ax, i in zip(axs[1], indx):\n",
    "        ax.imshow(fives[i].reshape(28, 28), cmap=\"gray\", vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your data\n",
    "\n",
    "x_train, y_train = load_data(\"dataset_numbers_train.npy\")\n",
    "plot_numbers(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942332bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(X: ArrayLike, y: ArrayLike, w: ArrayLike, b: float) -> float:\n",
    "    \"\"\"Computes the log loss.\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n,d).\n",
    "        y (ArrayLike): The labels of shape (n,).\n",
    "        w (ArrayLike): The weights of shape (d,).\n",
    "        b (float): The intercept.\n",
    "    Returns:\n",
    "        float: The log loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement the log loss.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(\n",
    "    X: ArrayLike, y: ArrayLike, lam: float = 0\n",
    ") -> linear_model.LogisticRegression:\n",
    "    \"\"\"Fit an instance of Logistic Regression.\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n,d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "    Returns:\n",
    "        LogisticRegression: The fitted Logistic Regression model.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement the logistic regression using scikit-learn. !!!Read the task at the top of this notebook!!!\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(x: ArrayLike, y: ArrayLike, lam: float, k: int = 10) -> tuple[float, float]:\n",
    "    \"\"\"Performs k-fold cross-validation to evaluate the model's performance.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lam (float): The regularization parameter.\n",
    "        k (int, optional): The number of folds. Defaults to 10.\n",
    "    Returns:\n",
    "        tuple[float, float]: Average train and validation scores ¡¡PER DATA POINT!!.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure k is not greater than the number of samples\n",
    "    assert k <= x.shape[0], \"k cannot be greater than the number of samples.\"\n",
    "    assert k > 1, \"k must be greater than 1.\"\n",
    "\n",
    "    train_acc_value = 0.0\n",
    "    val_acc_value = 0.0\n",
    "    for train_index, valid_index in KFold(n_splits=k, shuffle=True).split(x, y):\n",
    "        x_train = x[train_index]\n",
    "        y_train = y[train_index]\n",
    "\n",
    "        x_valid = x[valid_index]\n",
    "        y_valid = y[valid_index]\n",
    "\n",
    "        model = logistic_regression(x_train, y_train, lam=lam)\n",
    "\n",
    "        train_acc_value += model.score(x_train, y_train)\n",
    "        val_acc_value += model.score(x_valid, y_valid)\n",
    "\n",
    "    avg_train_loss = train_acc_value / k\n",
    "    avg_val_loss = val_acc_value / k\n",
    "\n",
    "    return avg_train_loss, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_curve_data(\n",
    "    x: ArrayLike, y: ArrayLike, lambdas: ArrayLike\n",
    ") -> tuple[int, ArrayLike, ArrayLike]:\n",
    "    \"\"\"Computes the best lambda and returns its index and train and validation scores for lambdas.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lambdas (ArrayLike): The range of lambda values to evaluate.\n",
    "    Returns:\n",
    "        int: The best lambda index based on the validation score.\n",
    "        ArrayLike: The training scores for each lambda value.\n",
    "        ArrayLike: The validation scores for each lambda value.\n",
    "    \"\"\"\n",
    "\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    for lam in lambdas:\n",
    "        train_score, val_score = kfold(x, y, lam, k=10)\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "    return np.argmax(val_scores).item(), train_scores, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbd070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_curve(\n",
    "    lambdas: ArrayLike,\n",
    "    train_scores: ArrayLike,\n",
    "    val_scores: Optional[ArrayLike] = None,\n",
    "    score_name: str = \"Accuracy\",\n",
    ") -> None:\n",
    "    \"\"\"Plots the score curve.\n",
    "    Args:\n",
    "        lambdas (ArrayLike): The regularization values.\n",
    "        train_scores (ArrayLike): The training scores.\n",
    "        val_scores (ArrayLike, optional): The validation scores. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(\n",
    "        lambdas,\n",
    "        train_scores,\n",
    "        color=\"#D81B60\",\n",
    "        linewidth=2.5,\n",
    "        label=f\"Train {score_name}\",\n",
    "    )\n",
    "    if val_scores is not None:\n",
    "        plt.plot(\n",
    "            lambdas,\n",
    "            val_scores,\n",
    "            color=\"#1E88E5\",\n",
    "            linewidth=2.5,\n",
    "            label=f\"Valid {score_name}\",\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(f\"{score_name}\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-4, 0, num=30, base=10)\n",
    "best_lam_idx, train_scores, val_scores = get_score_curve_data(x_train, y_train, lambdas)\n",
    "print(f\"Best inverse lambda (C): {lambdas[best_lam_idx]}\")\n",
    "print(f\"Train accuracy: {train_scores[best_lam_idx]:.8f}\")\n",
    "print(f\"Validation accuracy: {val_scores[best_lam_idx]:.8f}\")\n",
    "\n",
    "plot_score_curve(\n",
    "    lambdas,\n",
    "    train_scores,\n",
    "    val_scores,\n",
    ")\n",
    "\n",
    "model = logistic_regression(x_train, y_train, lam=lambdas[best_lam_idx])\n",
    "print(f\"Train accuracy: {model.score(x_train, y_train)}\")\n",
    "\n",
    "x_test, y_test = load_data(\"dataset_numbers_test.npy\")\n",
    "print(f\"Test accuracy: {model.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15afae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
