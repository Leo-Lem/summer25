{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5546d534",
   "metadata": {},
   "source": [
    "# Lasso Regression / Ridge Regression / Least-Squares Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ef2ed5",
   "metadata": {},
   "source": [
    "Consider the following regression problem: You are given 40 data points each having 200 features and a real-valued response for each data point.\n",
    "\n",
    "To find a good linear regressor, that explains the data well and at the same time is fairly sparse, you can use lasso regression.\n",
    "\n",
    "You encounter such problems usually when dealing with gene expression data where you have few patients but many genes that might cause an illness.\n",
    "\n",
    "\n",
    "In this programming exercise, you will compare least-squares, ridge and lasso regression, and familiarize yourself with the scikit-learn library.\n",
    "\n",
    "The template provided in this notebook already has the least-squares and ridge regression implemented from previous exercises.\n",
    "\n",
    "- Implement lasso regression using the scikit-learn library. Assume that the data is centered and use a maximum iteration count of 10000 for optimizers.\n",
    "\n",
    "- Implement the visualization of the regularization path.\n",
    "\n",
    "- Compare the validation curves and regularization paths of least-squares, ridge and lasso regression.\n",
    "    - What are differences and similarities between the three methods?\n",
    "    - How do the validation curves and regularization paths correspond to each other?\n",
    "\n",
    "When done, paste the code into the quiz on Moodle and answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882b89b",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be876cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a83f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Loads data from provided .npy files and returns the X and y values.\n",
    "    Args:\n",
    "        name (str): The file name of the .npy file to load.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The X and y values of the data. X has shape (n,d) and y has shape (n,).\n",
    "    \"\"\"\n",
    "    data = np.load(name)\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed843b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X: ArrayLike, y: ArrayLike) -> tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"Shuffles the data using a random permutation.\n",
    "    Args:\n",
    "        X (ArrayLike): The input values of the data.\n",
    "        y (ArrayLike): The target values of the data.\n",
    "    Returns:\n",
    "        tuple[ArrayLike, ArrayLike]: The shuffled X and y values.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    n = X.shape[0]\n",
    "    indx = rng.permutation(n)\n",
    "    return X[indx, :], y[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(\n",
    "    lambdas: ArrayLike,\n",
    "    train_losses: ArrayLike,\n",
    "    val_losses: Optional[ArrayLike] = None,\n",
    ") -> None:\n",
    "    \"\"\"Plots the validation curve.\n",
    "    Args:\n",
    "        lambdas (ArrayLike): The regularization values.\n",
    "        train_losses (ArrayLike): The training losses.\n",
    "        val_losses (ArrayLike, optional): The validation losses. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(lambdas, train_losses, color=\"#D81B60\", linewidth=2.5, label=\"Train loss\")\n",
    "    if val_losses is not None:\n",
    "        plt.plot(\n",
    "            lambdas, val_losses, color=\"#1E88E5\", linewidth=2.5, label=\"Valid loss\"\n",
    "        )\n",
    "    plt.legend()\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation Curve\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda894e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regularization_path(\n",
    "    lambdas: ArrayLike,\n",
    "    coefs: ArrayLike,\n",
    ") -> None:\n",
    "    \"\"\"Plots the regularization path.\n",
    "\n",
    "    Args:\n",
    "        lambdas (ArrayLike): The regularization values.\n",
    "        coefs (ArrayLike): The coefficients of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.plot(lambdas, coefs, linewidth=2.5)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Lambda\")\n",
    "    plt.ylabel(\"Coefficients\")\n",
    "    plt.title(\"Regularization Path\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_regression(X: ArrayLike, y: ArrayLike, lam: float = 0) -> ArrayLike:\n",
    "    \"\"\"Calculates the linear least-squares regression coefficients.\n",
    "\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n,).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "\n",
    "    Returns:\n",
    "        ArrayLike: The linear regression coefficients.\n",
    "    \"\"\"\n",
    "    w = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    # w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    # w = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b4afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X: ArrayLike, y: ArrayLike, lam: float = 0) -> ArrayLike:\n",
    "    \"\"\"Calculates the Ridge Regression (linear least-squares regression with l2-regularization) coefficients.\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "    Returns:\n",
    "        ArrayLike: The ridge regression coefficients.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    w = np.linalg.lstsq(X.T @ X + n * lam * np.eye(d), X.T @ y)[0]\n",
    "    # w = np.linalg.inv(X.T @ X + X.shape[0] * lam * np.eye(X.shape[1])) @ X.T @ y\n",
    "    # w = np.linalg.solve(X.T @ X + X.shape[0] * lam * np.eye(X.shape[1]), X.T @ y)\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f00e9c",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a44a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regression(X: ArrayLike, y: ArrayLike, lam: float = 0) -> ArrayLike:\n",
    "    \"\"\"Calculates the Lasso Regression (linear least-squares regression with l1-regularization) coefficients.\n",
    "\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "    Returns:\n",
    "        ArrayLike: The lasso regression coefficients.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement Lasso regression using sklearn. !!!Read the task at the top of this notebook!!!\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a08c0",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547e4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_loss(X: ArrayLike, y: ArrayLike, w: ArrayLike) -> float:\n",
    "    \"\"\"Calculates the loss of the linear least squares regression.\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        w (ArrayLike): The weights of the model.\n",
    "    Returns:\n",
    "        float: The loss of the linear least squares regression.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    return np.linalg.norm(X @ w - y) ** 2 / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5be12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(x: ArrayLike, y: ArrayLike, lam: float, k: int = 10, regression: Callable[[ArrayLike, ArrayLike, float], ArrayLike] = ridge_regression) -> tuple[float, float]:\n",
    "    \"\"\"Performs k-fold cross-validation to evaluate the model's performance.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lam (float): The regularization parameter.\n",
    "        k (int, optional): The number of folds. Defaults to 10.\n",
    "    Returns:\n",
    "        tuple[float, float]: Average train and validation losses ¡¡PER DATA POINT!!.\n",
    "    \"\"\"\n",
    "    # Ensure k is not greater than the number of samples\n",
    "    assert k <= x.shape[0], \"k cannot be greater than the number of samples.\"\n",
    "    assert k > 1, \"k must be greater than 1.\"\n",
    "\n",
    "    n = x.shape[0]\n",
    "    split_indices = np.array_split(range(n), k)\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for val_indices in split_indices:\n",
    "        # Remove fold from training data\n",
    "        train_x = np.delete(x, val_indices, axis=0)\n",
    "        train_y = np.delete(y, val_indices)\n",
    "\n",
    "        # Set fold to validation data\n",
    "        valid_x = x[val_indices, :]\n",
    "        valid_y = y[val_indices]\n",
    "\n",
    "        w = regression(train_x, train_y, lam=lam)\n",
    "\n",
    "        train_loss = empirical_loss(train_x, train_y, w)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = empirical_loss(valid_x, valid_y, w)\n",
    "        valid_losses.append(val_loss)\n",
    "\n",
    "    # Each datapoint appeared k-1 times as training point\n",
    "    avg_train_loss = np.sum(train_losses) / (n * (k - 1))\n",
    "    avg_val_loss = np.sum(valid_losses) / n\n",
    "\n",
    "    return avg_train_loss.item(), avg_val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c936be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_curve_data(\n",
    "    x: ArrayLike, \n",
    "    y: ArrayLike, \n",
    "    lambdas: ArrayLike, \n",
    "    regression: Callable[[ArrayLike, ArrayLike, float], ArrayLike]\n",
    ") -> tuple[int, ArrayLike, ArrayLike]:\n",
    "    \"\"\"Computes the best lambda and returns its index and train and validation losses for lambdas.\n",
    "    Args:\n",
    "        x (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lambdas (ArrayLike): The range of lambda values to evaluate.\n",
    "        regression (Callable[[ArrayLike, ArrayLike, float], ArrayLike]): The regression function to use.\n",
    "    Returns:\n",
    "        int: The best lambda index based on the validation loss.\n",
    "        ArrayLike: The training losses for each lambda value.\n",
    "        ArrayLike: The validation losses for each lambda value.\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for lam in lambdas:\n",
    "        train_loss, val_loss = kfold(x, y, lam, k=10, regression=regression)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    return np.argmin(val_losses).item(), train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a3e35",
   "metadata": {},
   "source": [
    "# Regularization path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a733bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regularization_path_data(\n",
    "    X: ArrayLike,\n",
    "    y: ArrayLike,\n",
    "    lambdas: ArrayLike,\n",
    "    regression: Callable[[ArrayLike, ArrayLike, float], ArrayLike]\n",
    ") -> ArrayLike:\n",
    "    \"\"\"Computes the regularization path for the given lambdas.\n",
    "    Args:\n",
    "        X (ArrayLike): The input data of shape (n, d).\n",
    "        y (ArrayLike): The output data of shape (n,).\n",
    "        lambdas (ArrayLike): The range of lambda values to evaluate.\n",
    "        regression (Callable[[ArrayLike, ArrayLike, float], ArrayLike]): The regression function to use.\n",
    "    Returns:\n",
    "        ArrayLike: The coefficients for each lambda value of shape (len(lambdas), d).\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement a function that returns data required for plotting the regularization path.\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e0747",
   "metadata": {},
   "source": [
    "# More stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for regression in [ridge_regression, lasso_regression, least_squares_regression]:\n",
    "    print(\"==========================\")\n",
    "    print(regression.__name__)\n",
    "    print(\"==========================\")\n",
    "\n",
    "    # Data loading and preprocessing\n",
    "    X_train, y_train = load_data(\"dataset_sparse_train.npy\")\n",
    "    X_train, y_train = shuffle_data(X_train, y_train)\n",
    "\n",
    "    # Validation curve\n",
    "    lambdas = np.logspace(-3, 5, num=100, base=10)\n",
    "    _, train_losses, val_losses = get_validation_curve_data(\n",
    "        X_train, y_train, lambdas, regression\n",
    "    )\n",
    "    plot_validation_curve(\n",
    "        lambdas,\n",
    "        train_losses,\n",
    "        val_losses,\n",
    "    )\n",
    "\n",
    "    # Regularization path\n",
    "    regularization_path = get_regularization_path_data(\n",
    "        X_train, y_train, lambdas, regression\n",
    "    )\n",
    "    plot_regularization_path(lambdas, regularization_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
